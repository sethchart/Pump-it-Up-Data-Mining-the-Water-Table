{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Modules\n",
    "Below we collect the tools that we will use to build our model. After initial exploratory modeling we found that `XGBClassifier` provided the best performance, measured in terms of model accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Random State\n",
    "The random state to be used whenever a randomized process is initiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Columns to Drop from the Model\n",
    "Provide a list of variables that should be dropped from the model. We have not observed any improvement in model performance from dropping data, measured in terms of accuracy. Training time is obviously improved by dropping columns but there seems to be a small price to pay in terms of accuracy for reducing the number of available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "Because of the submission format requirements for the competition, it is vital that we retain the index column through out modeling so that we are able to produce predictions that can be validated using the competition's validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/training_features.csv', index_col='id')\n",
    "targets = pd.read_csv('../data/training_labels.csv', index_col='id')\n",
    "df = features.join(targets, how='left')\n",
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Train Split\n",
    "For the purposes of model tuning we hold 10% of the data out for local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation\n",
    "We experimented with both manual and automated feature selection, however neither approach improved model performance. Initially, we has issues with mixed data types in both the `public_meeting` and `permit` columns. The function below converts all categorical variables to strings to eliminate thoes errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_to_string(data):\n",
    "    return pd.DataFrame(data).astype(str)\n",
    "\n",
    "CategoricalTypeConverter = FunctionTransformer(convert_categorical_to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Variables\n",
    "We will need to pre-process our data in preparation for classification. Pre-processing is different for categorical and numerical variables. In order to implement different pre-pricessing flows, we must first classify all of our variables as categorical or numerical. The function below separates columns into these two classes and excludes any variables that will be dropped from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_columns(df, drop_cols):\n",
    "    \"\"\"Takes a dataframe and a list of columns to drop and returns:\n",
    "        - cat_cols: A list of categorical columns.\n",
    "        - num_cols: A list of numerical columns.\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "    keep_cols = [col for col in cols if col not in drop_cols]\n",
    "    cat_cols = []\n",
    "    num_cols = []\n",
    "    for col in keep_cols:\n",
    "        if df[col].dtype == object:\n",
    "            cat_cols.append(col)\n",
    "        else:\n",
    "            num_cols.append(col)\n",
    "    return cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, num_cols = classify_columns(X_train, drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Preprocessor\n",
    "Below we build a preprocessing step for our pipeline which handles all data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Pipeline\n",
    "The pipeline below executes the following three steps for all of our categorical data.\n",
    "1. Convert all values in categorical columns to strings. This avoids data type errors in the following steps.\n",
    "2. Fill all missing values with the string `missing`.\n",
    "3. One-hot encode all categorical variables. Because this data contains categorical variables with many possible values, it is possible to encounter values in testing data that was not present in the training data. For this reason, we need to set `handel_unknown` to `ignore` so that the encoder will simply ignore unknown values in testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('typeConverter', CategoricalTypeConverter),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('standardizer', OneHotEncoder(handle_unknown='ignore',dtype=float))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Pipeline\n",
    "The pipeline below executes two steps:\n",
    "1. Imputes missing values in any numerical column with the median value from that column.\n",
    "2. Scales each variable to have mean zero and standard deviation one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('standardizer', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessor\n",
    "The column transformer below implements each of the three possible pre-processing behaviors. \n",
    "1. Apply the categorical pipeline.\n",
    "2. Apply the numerical pipeline.\n",
    "3. Drop the specified columns.\n",
    "The if-then statement below ensures that the drop processor is only implemented if there are columns to drop. This is needed since passing an empty `drop_col` list throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(drop_cols) > 0:\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numericalPreprocessor', numerical_pipeline, num_cols),\n",
    "        ('categoricalPreprocessor', categorical_pipeline, cat_cols),\n",
    "        ('dropPreprocessor', 'drop', drop_cols)\n",
    "    ])\n",
    "else:\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numericalPreprocessor', numerical_pipeline, num_cols),\n",
    "        ('categoricalPreprocessor', categorical_pipeline, cat_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Pipeline\n",
    "Below we build our main pipeline which executes two steps.\n",
    "1. Apply preprocessing to the raw data.\n",
    "2. Fit a one vs rest classifier to the processed data using an eXtreme Gradient Boosted forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', OneVsRestClassifier(estimator='passthrough'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Parameter Grid\n",
    "Below we define a grid of hyper-parameters for our pipeline that will be tested in a grid search below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = [\n",
    "    {\n",
    "        'classifier__estimator': [DecisionTreeClassifier()],\n",
    "        'classifier__estimator__max_depth': [5],\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate Grid Search\n",
    "Below we instantiate a grid search object which will fit our pipeline for every combination of the parameters defined above. Since the competition uses accuracy as it's measure of model quality, we sill evaluate model performance in terms of accuracy. For each parameter combination, the grid search will also execute five-fold cross validation. \n",
    "\n",
    "In order to maximize performance, we will fit our grid search on the full provided training data set and select our best hyper-parameters based on the results of cross validation. For the purposes of local model evaluation, we will then refit the best model on our local training data and use our local testing data to produce a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline, \n",
    "    param_grid=parameter_grid, \n",
    "    scoring='accuracy', \n",
    "    cv=5, \n",
    "    verbose=2, \n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Grid Search\n",
    "Below we fit our grid search on the full training set and select the best model hyper-parameters. This step takes an Extremely long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.2s finished\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X, y)\n",
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Results of Grid Search\n",
    "Below we display the results of our grid search. We pay particular attention to `std_test_score` which will become larger if the model is over-fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__estimator</th>\n",
       "      <th>param_classifier__estimator__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.227238</td>\n",
       "      <td>1.31484</td>\n",
       "      <td>0.502048</td>\n",
       "      <td>0.16364</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=5)</td>\n",
       "      <td>5</td>\n",
       "      <td>{'classifier__estimator': DecisionTreeClassifi...</td>\n",
       "      <td>0.714815</td>\n",
       "      <td>0.71835</td>\n",
       "      <td>0.721044</td>\n",
       "      <td>0.717256</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.718737</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       6.227238       1.31484         0.502048         0.16364   \n",
       "\n",
       "           param_classifier__estimator param_classifier__estimator__max_depth  \\\n",
       "0  DecisionTreeClassifier(max_depth=5)                                      5   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__estimator': DecisionTreeClassifi...           0.714815   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0            0.71835           0.721044           0.717256           0.722222   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.718737        0.002653                1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "r = permutation_importance(model, X, y,\n",
    "                           n_repeats=5,\n",
    "                           random_state=random_state,\n",
    "                           n_jobs=-1\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waterpoint_type          : 0.108844 +/- 0.001505\n",
      "quantity_group           : 0.035690 +/- 0.000202\n",
      "quantity                 : 0.035443 +/- 0.000094\n",
      "amount_tsh               : 0.007290 +/- 0.000349\n",
      "longitude                : 0.006111 +/- 0.000133\n",
      "region_code              : 0.005365 +/- 0.000218\n",
      "extraction_type_class    : 0.004989 +/- 0.000179\n",
      "lga                      : 0.004618 +/- 0.000132\n",
      "scheme_name              : 0.004102 +/- 0.000207\n",
      "source_type              : 0.003934 +/- 0.000214\n",
      "funder                   : 0.003238 +/- 0.000057\n",
      "ward                     : 0.002295 +/- 0.000021\n",
      "public_meeting           : 0.002088 +/- 0.000131\n",
      "payment                  : 0.001543 +/- 0.000147\n",
      "latitude                 : 0.000847 +/- 0.000092\n",
      "region                   : 0.000786 +/- 0.000052\n",
      "installer                : 0.000572 +/- 0.000048\n",
      "extraction_type          : 0.000483 +/- 0.000042\n",
      "population               : 0.000393 +/- 0.000029\n",
      "source                   : 0.000185 +/- 0.000055\n",
      "water_quality            : 0.000146 +/- 0.000052\n",
      "subvillage               : 0.000140 +/- 0.000008\n",
      "construction_year        : 0.000101 +/- 0.000000\n",
      "wpt_name                 : 0.000084 +/- 0.000000\n",
      "date_recorded            : 0.000067 +/- 0.000000\n",
      "permit                   : 0.000056 +/- 0.000016\n",
      "scheme_management        : 0.000039 +/- 0.000008\n"
     ]
    }
   ],
   "source": [
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{X.columns[i]:<25}: \"\n",
    "              f\"{r.importances_mean[i]:.6f}\"\n",
    "              f\" +/- {r.importances_std[i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flatiron",
   "language": "python",
   "name": "flatiron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
